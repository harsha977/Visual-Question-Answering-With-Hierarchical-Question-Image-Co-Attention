{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Final.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DfKzC0J9ZJzQ","colab_type":"text"},"source":["<center><h1>Visual Question Answering (VQA)</h1></center>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5KkSe7cWPyw8","colab":{}},"source":["#installing packages (since i'm using google colab,i'm installing from notebook itself)\n","\n","#%%capture\n","#!pip3 install --upgrade tensorflow-gpu\n","#!pip install tensorflow --upgrade"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gq7CEMgkyyjM","colab_type":"code","colab":{}},"source":["#importing packages\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HpB474_ozNlj","colab_type":"text"},"source":["<h1>Mounting the Drive </h1>"]},{"cell_type":"code","metadata":{"id":"5zrTAHFYyyjY","colab_type":"code","outputId":"2223d954-3f20-4caf-9522-b547cd8c09b7","executionInfo":{"status":"ok","timestamp":1590749597514,"user_tz":-330,"elapsed":2097,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["drive.mount('/content/drive/', force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5p6q1p4Eyyjc","colab_type":"text"},"source":["<h1>Variables</h1>"]},{"cell_type":"code","metadata":{"id":"fWk4PxVvyyjd","colab_type":"code","colab":{}},"source":["currentDirectory = \"/content/drive/My Drive/pcase_study_2/\"\n","os.chdir(currentDirectory)\n","currentDirectory = \"\"\n","dataDirectory = currentDirectory + \"data/\"\n","imageDirectory = dataDirectory + \"train2014/\"\n","imageNumpyDirectory = dataDirectory + \"VGG19_Numpy/\"\n","modelsDirectory = currentDirectory + \"Models/\"\n","img_width = 448\n","img_height = 448\n","\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 300\n","\n","#while True:\n","#    try:\n","#        print(len(os.listdir(imageDirectory)))\n","#        break\n","#    except:\n","#        print(\"Buffer Error\")\n","#        continue"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PbqpeLF4FVXX","colab_type":"code","colab":{}},"source":["X_val = pd.read_csv(dataDirectory + 'X_val.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pac4sR54Fk7L","colab_type":"code","colab":{}},"source":["def final_fun_1(X):\n","    \"\"\"\n","    X Must have two elements \n","    1) array of image paths \n","    2) array of questions\n","    \"\"\"\n","    from PythonModules.vqa import VQA, images_to_numpy, get_tokenizer_labelEncoder\n","\n","    images, questions = X[0], X[1]\n","    #Reading the model\n","    model = VQA()\n","    #loading saved weights\n","    model.load_weights(modelsDirectory  + \"Coattention/best_03.hdf5\")\n","    #reading the tokenizer and encoder\n","    tokenizer, label_encoder = get_tokenizer_labelEncoder()\n","\n","    #featurizing images using VGG Model\n","    image_features  = images_to_numpy(images)\n","\n","    #featurizing questions\n","    question_features = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(questions),padding='post',maxlen=24)\n","\n","    #Getting predictions from the model\n","    y_pred = model.predict([image_features,question_features], verbose = 1, batch_size = 64)\n","\n","    #converting predictions to class labels\n","    class_indices = tf.math.top_k(y_pred,k=1).indices.numpy()\n","    predictions = []\n","    for idx,i in enumerate(class_indices):\n","        classes = np.zeros((1,1000))\n","        classes[0][i] = 1\n","        predictions.append(label_encoder.inverse_transform(classes)[0])\n","\n","    #retuting predicted class label's\n","    return np.array(predictions)\n","\n","\n","def final_fun_2(X, y):\n","    \"\"\"\n","    X Must have two elements \n","    1) array of image paths \n","    2) array of questions\n","    y => array of class labels\n","    \"\"\"\n","    from PythonModules.vqa import VQA, images_to_numpy, get_tokenizer_labelEncoder\n","\n","    images, questions = X[0], X[1]\n","    #Reading the model\n","    model = VQA()\n","    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","    #loading saved weights\n","    model.load_weights(modelsDirectory  + \"Coattention/best_03.hdf5\")\n","    #reading the tokenizer and encoder\n","    tokenizer, label_encoder = get_tokenizer_labelEncoder()\n","\n","    #featurizing images using VGG Model\n","    image_features  = images_to_numpy(images)\n","\n","    #featurizing questions\n","    question_features = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(questions),padding='post',maxlen=24)\n","\n","    #encoding class labels\n","    y = label_encoder.transform(y)\n","    y = y.toarray()\n","\n","    #Getting metrics from the model\n","    metrics = model.evaluate(x = [image_features,question_features], y = y, verbose = 1, batch_size = 64)\n","\n","    #retuting metrics \n","    return metrics[0],metrics[1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySqJB3DAIO_6","colab_type":"code","colab":{}},"source":["image_paths = X_val['image_id'].apply(lambda x:  imageDirectory + 'COCO_train2014_' + '%012d.jpg' % (x)).values\n","questions = X_val['question'].values\n","answers = X_val['multiple_choice_answer']\n","\n","X = (image_paths[:100], questions[:100])\n","y = answers[:100]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mqpLQm-GIPIk","colab_type":"code","outputId":"e3c2ccd2-7275-48bd-fa8c-89b9af6c6fe8","executionInfo":{"status":"ok","timestamp":1590752143871,"user_tz":-330,"elapsed":7161,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["predicted_classes = final_fun_1(X)\n","print(predicted_classes)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2/2 [==============================] - 1s 396ms/step\n","2/2 [==============================] - 0s 9ms/step\n","['no' '1' 'multi' 'yes' 'bicycles' 'blue' '1' 'grazing' 'yes' 'no' 'night'\n"," 'grass' 'hat' 'stop' 'strawberry' 'yes' 'ocean' '2' 'yes' 'kitchen' 'no'\n"," 'yes' '3' 'yes' 'motorcycle' 'no' 'pink' 'car' 'no' 'bus stop' 'none'\n"," 'brown' 'shirt' 'white' 'yes' 'yes' 'clay' 'sand' 'books' 'windows' 'no'\n"," 'eating' 'yes' 'no' 'bed' 'grapes' '1' 'no' '1' 'yes' 'no' 'no' 'no' '1'\n"," 'yes' '12:00' 'yes' 'yes' 'yes' 'white' 'no' 'surf' 'red' 'no' 'no'\n"," 'metal' '1' '2' 'no' '3' 'cigarette' '2' 'old' 'no' 'yes' 'on desk'\n"," 'sunny' 'parrot' 'a' 'no' 'yes' 'yes' 'yes' 'baseball' 'white' 'no' 'no'\n"," 'black' 'yes' '1' 'left' '1' 'yes' 'no' 'drinking' 'yes' 'yes' '1' 'yes'\n"," 'red']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VtREK4mVLwsm","colab_type":"code","outputId":"b8362781-6cf1-49d9-d27c-4c4cb7342768","executionInfo":{"status":"ok","timestamp":1590752153740,"user_tz":-330,"elapsed":8266,"user":{"displayName":"Harshavardhan Reddy","photoUrl":"","userId":"04818827080319198541"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["loss, accuracy = final_fun_2(X, y)\n","print(\"Loss: \",loss)\n","print(\"Accuracy: \",accuracy)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2/2 [==============================] - 1s 399ms/step\n","2/2 [==============================] - 0s 9ms/step - loss: 1.5448 - accuracy: 0.3900\n","Loss:  1.5448129177093506\n","Accuracy:  0.38999998569488525\n"],"name":"stdout"}]}]}